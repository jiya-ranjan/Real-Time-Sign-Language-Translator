# ğŸ–ï¸ Real-Time Sign Language Translator  
**AI-powered real-time gesture recognition using Convolutional Neural Networks and OpenCV**

> A deep learning application that translates sign language hand gestures into English alphabets in real-time using a webcam feed.

---

## ğŸš€ Overview

The **Real-Time Sign Language Translator** captures hand gestures via webcam and predicts the corresponding English alphabet using a **Convolutional Neural Network (CNN)** model trained on the **Sign Language MNIST dataset**.  
The trained model is deployed using **ONNX Runtime** and **OpenCV** for efficient real-time inference.

---

## âœ¨ Key Features

- ğŸ§  **Deep Learning Model:** CNN trained on Sign Language MNIST dataset  
- ğŸ“¸ **Real-Time Detection:** Uses webcam feed for live prediction  
- âš¡ **Fast Inference:** Model deployed with ONNX Runtime for high-speed results  
- ğŸ¯ **High Accuracy:** Achieved 90%+ real-time classification accuracy  
- â™¿ **Accessibility Impact:** Enables gesture-based communication for the hearing-impaired  

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|------------|-------------|
| **Language** | Python |
| **Frameworks** | PyTorch, ONNX Runtime |
| **Computer Vision** | OpenCV |
| **Dataset** | Sign Language MNIST |
| **Other Tools** | NumPy, Matplotlib |

---
## âš™ï¸ How It Works

1. **Data Preparation:** Load and preprocess the Sign Language MNIST dataset.  
2. **Model Training:** Train a CNN to classify hand signs (Aâ€“Z).  
3. **Model Conversion:** Export trained model to ONNX format.  
4. **Live Detection:** Use `OpenCV` to capture video frames and run ONNX inference.  

---
##ğŸ“ˆ Results

âœ… 90%+ accuracy on test dataset

ğŸ¥ Real-time translation with minimal latency

ğŸ“Š Consistent performance across various lighting conditions
