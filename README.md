# ğŸ–ï¸ Real-Time Sign Language Translator  
**AI-powered real-time gesture recognition using Convolutional Neural Networks and OpenCV**

> A deep learning application that translates sign language hand gestures into English alphabets in real-time using a webcam feed.

---

## ğŸš€ Overview

The **Real-Time Sign Language Translator** captures hand gestures via webcam and predicts the corresponding English alphabet using a **Convolutional Neural Network (CNN)** model trained on the **Sign Language MNIST dataset**.  
The trained model is deployed using **ONNX Runtime** and **OpenCV** for efficient real-time inference.

---

## âœ¨ Key Features

- ğŸ§  **Deep Learning Model:** CNN trained on Sign Language MNIST dataset  
- ğŸ“¸ **Real-Time Detection:** Uses webcam feed for live prediction  
- âš¡ **Fast Inference:** Model deployed with ONNX Runtime for high-speed results  
- ğŸ¯ **High Accuracy:** Achieved 90%+ real-time classification accuracy  
- â™¿ **Accessibility Impact:** Enables gesture-based communication for the hearing-impaired  

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|------------|-------------|
| **Language** | Python |
| **Frameworks** | PyTorch, ONNX Runtime |
| **Computer Vision** | OpenCV |
| **Dataset** | Sign Language MNIST |
| **Other Tools** | NumPy, Matplotlib |

---
